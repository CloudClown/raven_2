/***************************************
 *
 * File: local_io.c
 *

Local_io keeps its own copy of DS1 for incorporating new
network-layer and toolkit updates.

The local DS1 copy is protected by a mutex.

This transient copy should then be read to another copy for
active use.

***************************************/

///TODO: Modify the guts of local comm and network layer
#ifndef _GNU_SOURCE
#define _GNU_SOURCE //For realtime posix support. see http://www.gnu.org/s/libc/manual/html_node/Feature-Test-Macros.html
#endif

#include "log.h"
#include <string.h>
#include <pthread.h>
#include "local_io.h"
#include "mapping.h"

extern int NUM_MECH;
extern USBStruct USBBoards;
extern unsigned long int globalTime;

static struct param_pass data1;
pthread_mutexattr_t data1MutexAttr;
pthread_mutex_t data1Mutex;

volatile int isUpdated; //volatile int instead of atomic_t ///Should we use atomic builtins? http://gcc.gnu.org/onlinedocs/gcc-4.1.2/gcc/Atomic-Builtins.html

// initialize data arrays to zero
// create mutex
int initData(void)
{
    int i;
    pthread_mutexattr_init(&data1MutexAttr);
    pthread_mutexattr_setprotocol(&data1MutexAttr,PTHREAD_PRIO_INHERIT);
    pthread_mutex_init(&data1Mutex,&data1MutexAttr);

    pthread_mutex_lock(&data1Mutex);
    for (i=0;i<NUM_MECH;i++)
    {
        data1.xd[i].x = 0;
        data1.xd[i].y = 0;
        data1.xd[i].z = 0;
        data1.rd[i].yaw = 0;
        data1.rd[i].pitch = 0;
        data1.rd[i].roll = 0;
        data1.rd[i].grasp = 0;
    }
    data1.surgeon_mode=0;
    pthread_mutex_unlock(&data1Mutex);
    return 0;
}

// recvMaster()
//
//  Async function called when data from master is rec'd.
//
void recvMaster(struct u_struct *u)
{
    isUpdated = TRUE;
    teleopIntoDS1(u);
}

// Send local data to network layer
void putLocalData(struct robot_device *dev)
{
    static int seqnum;
    struct v_struct vs = {0,0,0,0,0,0};  // Teleoperation DS

    vs.sequence = seqnum;
    ///TODO: Fix this for preempt
    //  putFIFOData(CMDF2, dev);
    //  putFIFODataSized(CMDF0, &vs,sizeof(struct v_struct));

    seqnum++;
    return;
}

// ------------------------- //
// - Recieve toolkit data  - //
//-------------------------- //
int recieveToolkit(int fifo) //was unsigned int fifo
{
    struct param_pass ds1Recv;
    int ret;

    ret=read(fifo, &ds1Recv, sizeof(struct param_pass));
    if ( ret != sizeof( struct param_pass) )
    {
        log_msg("Bogus toolkit data on FIFO Rcv.  Resetting fifo.\n");
        return -1;
    }

    updateDS1(&ds1Recv);

    return 0;
}

// --------------------------- //
// - Recieve userspace data  - //
//---------------------------- //
//int recieveUserspace(unsigned int fifo)
int recieveUserspace(void *u,int size)
{
    int uSize=sizeof(struct u_struct);

    //recvMaster(&u);
    if (size==uSize)
    {
        recvMaster((struct u_struct*) u);
    }
    return 0;
}

// updateDS1()
//
//   update DS1 from toolkit update.
//
void updateDS1(struct param_pass *d1)
{
    int i;

    pthread_mutex_lock(&data1Mutex);

    // on entrance into RL=0, reset pos_d.
    for (i=0;i<NUM_MECH;i++)
    {
        if (d1->runlevel==0)
        {
            data1.xd[i].x = 0;
            data1.xd[i].y = 0;
            data1.xd[i].z = 0;
            data1.rd[i].yaw   =0;
            data1.rd[i].pitch =0;
            data1.rd[i].roll  =0;
            data1.rd[i].grasp =0;
        }
        // copy position data to new DS1 (rec'd from toolkit)
        //  The objective is to keep current position/orientation,
        //  while receiving commands (gains, trajectories, etc) from toolkit
        d1->xd[i].x = data1.xd[i].x;
        d1->xd[i].y = data1.xd[i].y;
        d1->xd[i].z = data1.xd[i].z;
        d1->rd[i].yaw   = data1.rd[i].yaw;
        d1->rd[i].pitch = data1.rd[i].pitch;
        d1->rd[i].roll  = data1.rd[i].roll;
        d1->rd[i].grasp  = data1.rd[i].grasp;
    }
    d1->surgeon_mode = data1.surgeon_mode;

    // copy new DS to local store
    memcpy(&data1, d1, sizeof(struct param_pass));
    isUpdated = TRUE;

    pthread_mutex_unlock(&data1Mutex);
}

// teleopIntoDS1()
//
//   Input from the master is put into DS1 as pos_d.
//
void teleopIntoDS1(struct u_struct *t)
{
    struct position p;
    int i;
    pthread_mutex_lock(&data1Mutex);
    for (i=0;i<NUM_MECH;i++)
    {
        if ( USBBoards.boards[i]==GREEN_ARM_SERIAL)
        {
            // apply mapping to teleop data
            p.x = t->delx[1];
            p.y = t->dely[1];
            p.z = t->delz[1];
            masterToSlave(&p, GREEN_ARM_SERIAL);
            data1.xd[i].x += p.x;
            data1.xd[i].y += p.y;
            data1.xd[i].z += p.z;

            data1.rd[i].yaw   += t->delyaw[1];
            data1.rd[i].pitch += t->delpitch[1];
            data1.rd[i].roll  += (t->delroll[1] * -1);  // Negated to align omni.
            data1.rd[i].grasp  = t->buttonstate[1];
        }
        else
        {
            // apply mapping to teleop data
            p.x = t->delx[0];
            p.y = t->dely[0];
            p.z = t->delz[0];
            masterToSlave(&p, GOLD_ARM_SERIAL);
            data1.xd[i].x += p.x;
            data1.xd[i].y += p.y;
            data1.xd[i].z += p.z;

            data1.rd[i].yaw   += t->delyaw[0];
            data1.rd[i].pitch += t->delpitch[0];
            data1.rd[i].roll  += (t->delroll[0] * -1);  // Negated to align omni.
            data1.rd[i].grasp  = t->buttonstate[0];
        }

        // LIMIT CHECK ON WRIST
        //  Note: Pitch is in integer microradians.
        //  ALSO: Pitch is multiplied by WRIST_SCALE_FACTOR before being used as jpos_d.
        if ( data1.rd[i].pitch < (int)(TOOL_WRIST_MIN_LIMIT * MICRORADS_PER_RAD / WRIST_SCALE_FACTOR))
        {
            data1.rd[i].pitch = TOOL_WRIST_MIN_LIMIT * MICRORADS_PER_RAD /WRIST_SCALE_FACTOR ;
        }
        else if ( data1.rd[i].pitch  > (int)(TOOL_WRIST_MAX_LIMIT * MICRORADS_PER_RAD / WRIST_SCALE_FACTOR))
        {
            data1.rd[i].pitch = TOOL_WRIST_MAX_LIMIT * MICRORADS_PER_RAD /WRIST_SCALE_FACTOR ;
        }

        // LIMIT CHECK ON ROLL
        if (data1.rd[i].roll < (int)(TOOL_ROLL_MIN_LIMIT * MICRORADS_PER_RAD) )
        {
            data1.rd[i].roll = TOOL_ROLL_MIN_LIMIT * MICRORADS_PER_RAD;
        }
        else if (data1.rd[i].roll > (int)(TOOL_ROLL_MAX_LIMIT * MICRORADS_PER_RAD))
        {
            data1.rd[i].roll = TOOL_ROLL_MAX_LIMIT * MICRORADS_PER_RAD;
        }


    }
    data1.surgeon_mode = t->surgeon_mode;
    pthread_mutex_unlock(&data1Mutex);
}

// checkLocalUpdates()
//
//  returns true if updates have been recieved from master or toolkit since last module update
//  returns false otherwise
//  Also, checks the last time updates were made from master.  If it has been to long
//  surgeon_mode state is set to pedal-up.
int checkLocalUpdates()
{
    static unsigned long int lastUpdated;

    if (isUpdated || lastUpdated == 0)
    {
        lastUpdated = globalTime;
    }
    else if (((globalTime-lastUpdated) > MASTER_CONN_TIMEOUT) && ( data1.surgeon_mode ))
    {
        // if timeout period is expired, set surgeon_mode "DISENGAGED" if currently "ENGAGED"
        log_msg("Master connection timeout.  surgeon_mode -> up.\n");
        data1.surgeon_mode = SURGEON_DISENGAGED;
        lastUpdated = globalTime;
        isUpdated = TRUE;
    }

    return isUpdated;
}

// Give the latest updated DS1 to the caller.
// Precondition: d1 is a pointer to allocated memory
// Postcondition: memory location of d1 contains latest DS1 Data from network/toolkit.
struct param_pass * getRcvdParams(struct param_pass* d1)
{
    ///TODO: Check performance of trylock / default priority inversion scheme
    if (pthread_mutex_trylock(&data1Mutex)!=0)   //Use trylock since this function is called form rt-thread. return immediately with old values if unable to lock
        return d1;
    //pthread_mutex_lock(&data1Mutex); //Priority inversion enabled. Should force completion of other parts and enter into this section.
    memcpy(d1, &data1, sizeof(struct param_pass));
    isUpdated = 0;
    pthread_mutex_unlock(&data1Mutex);
    return d1;
}

// Reset writable copy of DS1
void updateMasterRelativeOrigin(struct device *device0)
{
    int i;
    pthread_mutex_lock(&data1Mutex);

    // update data1 (network position desired) to device0.position_desired (device position desired)
    //   This eliminates accumulation of deltas from network while robot is idle.
    for (i=0;i<NUM_MECH;i++)
    {
        data1.xd[i].x = device0->mech[i].pos_d.x;
        data1.xd[i].y = device0->mech[i].pos_d.y;
        data1.xd[i].z = device0->mech[i].pos_d.z;
        data1.rd[i].yaw   = device0->mech[i].ori_d.yaw;
        data1.rd[i].pitch = device0->mech[i].ori_d.pitch;
        data1.rd[i].roll  = device0->mech[i].ori_d.roll;
        data1.rd[i].grasp = device0->mech[i].ori_d.grasp;
    }
    data1.surgeon_mode = 0;
    pthread_mutex_unlock(&data1Mutex);
    return;
}


/**Wrapper function called from real-time loop to copy device struct to output buffer. This function at present just calls another function
*that does this task.
*/
extern volatile struct v_struct v; //declared in network_layer.c
void putLocalData1(struct robot_device* dev)
{
    static int seqnum;
    struct v_struct vs ={0,0,0,0,0,0};  // Teleoperation DS

    copytoputbuffer(dev); //Copy struct to buffer

    vs.sequence = seqnum;
    memcpy((void *)&v,(void *)&vs,sizeof(struct v_struct)); ///TODO: This needs to have some form of locking.
    seqnum++;
}

//
///   Memory buffer functions for writing out of rt_loop
//

#define PUTDATABUF_SIZE 1024
struct device putdatabuf[PUTDATABUF_SIZE]; //Buffer of output data

volatile int putdatabuf_r=-1; //Initially no data available
volatile int putdatabuf_w=0; //Starting write location
volatile int currentwrdatabufop=0; //Index for current write operation
bool putdatawait=0;
pthread_mutexattr_t putdataMutexAttr;
pthread_mutex_t putdataMutex;

/** Initialize Mutex with priority inheritance for the putdata functions.
*/
void initputdataMutex()
{
    pthread_mutexattr_init(&putdataMutexAttr);
    pthread_mutexattr_setprotocol(&putdataMutexAttr,PTHREAD_PRIO_INHERIT); //Enable priority inheritance
    pthread_mutex_init(&putdataMutex,&putdataMutexAttr);
}

/**
*Sends the content of the output buffer to the FIFO on a FIFO basis.
*TODO: Locking mechanism for fifo write
*\param fd file descriptor
*/
void senddatafromoutputbuffer(int fd)
{
    write(fd,&putdatabuf[putdatabuf_r],sizeof(struct device));
    putdatabuf_r++;
    if (putdatabuf_r==PUTDATABUF_SIZE) //Wrap around to begining if we have moved beyond the end
    {
        putdatabuf_r=0;
    }
}

/**
*Copies the current device structure contents into the buffer on a FIFO basis
*TODO: Locking mechanism for fifo write
*\param dev robot device structure
*/
void copytoputbuffer(struct robot_device* dev)
{
    memcpy(&putdatabuf[putdatabuf_w], (void *)dev, sizeof(struct robot_device)); //copy to location pointed by write pointer
    if (putdatabuf_w==putdatabuf_r) //We have overwritten the oldest data with newest data. So increment pointer to next oldest data
    {
        putdatabuf_r++;
        if (putdatabuf_r==PUTDATABUF_SIZE) //Wrap around to begining if we have moved beyond the end
        {
            putdatabuf_r=0;
        }
    }
    putdatabuf_w++;
    if (putdatabuf_w==PUTDATABUF_SIZE) //Wrap around to begining if we have moved beyond the end
    {
        putdatabuf_w=0;
    }
}



#include <raven_2/raven_state.h>
using namespace raven_2;
// Global publisher for raven data
ros::Publisher pub_ravenstate;
int init_ravenstate_publishing(ros::NodeHandle &n){
    pub_ravenstate = n.advertise<raven_state>("ravenstate", 1000);
    return 0;
}

void publish_ravenstate_ros(struct robot_device *dev){

    static int count=0;
    static raven_state msg_ravenstate;  // satic variables to minimize memory allocation calls
    static ros::Time t1;
    static ros::Time t2;

    int numdof=6;
    for (int j=0; j<NUM_MECH; j++){
        for (int i=0; i<numdof; i++){
            msg_ravenstate.encVals[j*numdof+i] = dev->mech[j].joint[i].enc_val;
        }
    }
    if (count == 0){
        t1 = t1.now();
    }
    t2 = t2.now();

    msg_ravenstate.dt=t2-t1;
    t1=t2;

    pub_ravenstate.publish(msg_ravenstate);
    count ++;
}
